# 4. 실험 및 결과

## 4.1. 실험 환경 및 데이터

### 4.1.1. 실험 환경
본 논문에서 제안하는 모델은 Windows 10 환경의 PyCharm 프레임 워크를 기반으로 Python 언어를 통해 구현하였다. 심층 학습을 위한 라이브러리인 Tensorflow[18]와 Keras[19]를 사용하여 모델의 구조를 설계하였다. 그래픽 카드로는 GTX-1080(RAM 8G) 모델을 사용하였으며 GPU 병렬 연산 기능을 돕는 NVIDIA의 CUDA v8.0과 cuDNN v6.0을 활용하였다.

### 4.1.2. Celeb A
본 논문에서 제안하는 모델의 학습과 실험에 사용된 영상 데이터는 Ziwei Liu와 Ping Luo에 의해 수집된 CelebA(CelebFaces Atrributes Dataset)[20]을 사용하였다. CelebA는 202,599장의 다양한 포즈와 각도의 얼굴 영상으로 구성되어 있다. 본 논문의 모델 실험에서는 202,599장의 얼굴 영상 데이터 중 Haar 얼굴 검출 기법[21]으로 인식된 얼굴 정면 영상을 잘라낸 후 64×64 크기로 변경하여 사용하였다. 총 155,680장의 정면 얼굴 영상 중, 130,000장을 초해상도 복원 부분의 심층 신경망 학습에 이용하였으며, 나머지 25,680장의 영상을 영상 생성 실험 및 성능 평가에 활용하였다. VDSR 초해상도 복원 모델의 학습 영상으로는 3×3 크기의 필터로 blur 처리한 64×64 정면 얼굴 영상을 사용하였다. 그림 4.1은 CelebA 영상 데이터의 샘플 중 일부이며 (a)~(d)는 원본 영상이며 (e)~(h)는 각 영상에서 검출된 정면 얼굴 영상을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/48464697-bac87980-e823-11e8-9116-823de89b2f42.png)
<br/> _그림 4.1 CelebA 영상 데이터 샘플_

## 4.2. 실험 결과

### 4.2.1. 생성 영상 분석

제안하는 영상 생성 모델을 통해 생성된 영상을 표 4.2, 4.3, 4.4를 통해 나타내었다. 생성된 영상이 자연스럽고 실제 영상과 유사한 경우를 영상 생성에 성공한 사례로 표 4.2에 정리하였다. 표 4.3과 4.4에는 생성된 영상이 흐릿한 경우와 얼굴의 특징 생성이 부자연스러운 경우를 영상 생성에 실패한 사례로서 각각 정리하였다. 

영상 생성에 실패 사례가 생기는 이유를 분석하자면, CelebA 데이터에서 정면 얼굴 영상을 잘라내는 과정에서 학습 데이터 영상에 저화질 영상이 일부 포함되는 점과 대부분의 영상이 다양한 각도와 조명 아래에서 촬영되었으며 선글라스, 마이크와 같은 소품이나 조명의 방향에 의해 얼굴의 일부가 가려지는 영상이 있었던 점이 영향을 미친 것으로 판단된다. 

![image](https://user-images.githubusercontent.com/12293076/48464748-eb101800-e823-11e8-91c4-6c3ecd7eaa00.png)

#### 가) 영상 생성 성공 사례

![image](https://user-images.githubusercontent.com/12293076/48464771-067b2300-e824-11e8-89d2-9ef61f27fa87.png)

#### 나) 영상 생성 실패 사례

![image](https://user-images.githubusercontent.com/12293076/48464790-1561d580-e824-11e8-94c5-f3bd94960327.png)

![image](https://user-images.githubusercontent.com/12293076/48464805-23175b00-e824-11e8-9dfa-ef053d3ba3c1.png)

### 4.2.2. Inception Score 기반 성능 분석
본 논문의 영상 생성 방법에 대한 성능 평가 수단으로는 Inception Score[22]를 활용하였다. 테스트 데이터에 대한 정확도 분석으로 수행할 수 있는 구별 모델의 평가와 달리, 생성 모델으로 생성한 영상에 대한 평가를 객관화하기란 간단하지 않은 문제이다. Tim Sallmans가 제안한 Inception Score는 구별 모델 중 하나인 Inception V3[23] 모델을 이용하여 생성 모델의 성능을 평가하는 방법이다.

Inception V3 모델은 ImageNet 영상 데이터로 미리 학습된 가중치를 사용하며 그 구조는 Google 사의 GoogLeNet[24]의 구조를 확장하여 설계되었다. Inception Score는 Inception V3 모델을 이용하여 영상들을 분류하고, 그 결과가 일정할수록 정보 획득량(Information gain)이 많고 분류 결과가 다양하게 나올수록 정보 획득량이 적다는 사실을 이용하여 영상 생성 결과의 일관성을 수치화 한다. 수식 4.1은 Inception Score의 계산 방법을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/48464826-3b877580-e824-11e8-8899-adfe1327d554.png)

본 논문에서 제안하는 영상 생성 방법과 기존의 방법을 Inception Score를 통해 비교한 결과를 표 4.5에 정리하였다. Inception Score의 평균과 표준 편차를 계산에는 각 영상 생성 방법으로 생성한 10,000개의 서로 다른 영상을 이용하였다. VAE를 단독으로 사용하는 영상 생성 방법에 비해 VDSR 초해상도 복원 기법에 레지듀얼 블록 구조를 변경하고 PSNR 손실 함수를 적용한 본 논문의 제안 모델이 더 높은 Inception Score를 획득하여 생성 영상이 더욱 일관됨을 알 수 있다.

![image](https://user-images.githubusercontent.com/12293076/48465828-70e19280-e827-11e8-826b-62a4d6ce46b5.png)
