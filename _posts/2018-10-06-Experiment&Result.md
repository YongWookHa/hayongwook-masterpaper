
# 4. 실험 및 결과

## 4.1. 실험 환경 및 데이터

### 4.1.1. 실험 환경
본 논문에서 제안하는 모델은 Windows 10 환경의 PyCharm 프레임 워크를 기반으로 Python 언어를 통해 구현하였다. 심층 학습을 위한 라이브러리인 Tensorflow[18]와 Keras[19]를 사용하여 모델의 구조를 설계하였다. CPU는 Intel i7-6700K 모델을 사용하였다. 그래픽 카드로는 GTX-1080(RAM 8G) 모델을 사용하였으며 GPU 병렬 연산 기능을 돕는 NVIDIA의 CUDA v8.0과 cuDNN v6.0을 활용하였다. 100 학습 단계(Epoch)을 기준으로, VAE의 학습에 약 3시간, 초해상도 복원 모델의 학습에 약 56시간이 소요되었다. 학습된 모델으로 영상 생성 시, 같은 환경을 기준으로 100장의 영상을 생성하는데 약 0.72초의 시간이 소요되었다.

### 4.1.2. Celeb A
본 논문에서 제안하는 모델의 학습과 실험에 사용된 영상 데이터는 Ziwei Liu와 Ping Luo에 의해 수집된 CelebA(CelebFaces Atrributes Dataset)[20]을 사용하였다. CelebA는 202,599장의 다양한 포즈와 각도의 얼굴 영상으로 구성되어 있다. 본 논문의 모델 실험에서는 202,599장의 영상 데이터 중 Haar 얼굴 검출 기법[21]으로 인식된 총 155,680장의 정면 얼굴 영상을 잘라낸 후, 크기를 변경하여 사용하였다. VAE의 학습에는 64×64 크기로 변경한 155,680장의 정면 얼굴 영상을 모두 사용하였으며, 초해상도 복원 모델의 학습은 128×128 크기의 정면 얼굴 영상과 해당 영상을 3×3 크기의 필터로 blur 처리한 영상을 사용하였다. 130,000장의 영상을 초해상도 복원 모델의 학습에 이용하였고, 나머지 25,680장의 영상을 영상 생성 실험 및 성능 평가에 활용하였다. 그림 4.1은 CelebA 영상 데이터의 샘플 중 일부이며 (a)~(d)는 원본 영상이며 (e)~(h)는 각 영상에서 검출된 정면 얼굴 영상을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/50125785-b3c2da00-02ad-11e9-9ef6-4befc918e7e0.png)
<br/> _그림 4.1 CelebA 영상 데이터 샘플_

## 4.2. 실험 결과

### 4.2.1. 생성 영상 분석

생성된 영상 샘플을 그림 4.2를 통해 나타내었다. 제안하는 영상 생성 모델을 통해 생성된 대부분의 영상이 매우 사실적이고 또렷하게 생성됨을 확인할 수 있었다. 

표 4.1, 4.2에서는 생성된 영상을 분류하여 정리하였다. 영상이 심미적으로 자연스럽고 실제 영상과 유사한 경우를 영상 생성에 성공한 사례로 표 4.1에 정리하였다. 표 4.2에는 생성된 영상이 흐릿한 경우와 얼굴의 특징 생성이 부자연스러운 경우를 영상 생성에 실패한 사례로서 분류하였다. 

영상 생성에 실패 사례가 생기는 이유를 분석하자면, CelebA 데이터에서 정면 얼굴 영상을 잘라내는 과정에서 학습 데이터 영상에 저화질 영상이 일부 포함되는 점과 대부분의 영상이 다양한 각도와 조명 아래에서 촬영되었으며 선글라스, 마이크와 같은 소품이나 조명의 방향에 의해 얼굴의 일부가 가려지는 영상이 있었던 점이 영향을 미친 것으로 판단된다. 모델 학습에 방해가 되었을 것으로 의심되는 학습 영상 데이터 일부를 표 4.3을 통해 정리하였다.

#### 가) 생성 영상 샘플

![image](https://user-images.githubusercontent.com/12293076/50125807-bd4c4200-02ad-11e9-9112-960302aab16d.png)<br/> _그림 4.2 무작위로 선정한 생성 영상 샘플_

#### 나) 영상 생성 성공 사례

![image](https://user-images.githubusercontent.com/12293076/50125855-e53ba580-02ad-11e9-8718-3f92a006f091.png)

#### 다) 영상 생성 실패 사례

![image](https://user-images.githubusercontent.com/12293076/50125880-fc7a9300-02ad-11e9-992e-829aecdbfa49.png)

#### 라) 학습 방해 영상 사례

![image](https://user-images.githubusercontent.com/12293076/50125902-12885380-02ae-11e9-950e-226b421cece3.png)

### 4.2.2. Inception Score 기반 성능 분석
본 논문의 영상 생성 방법에 대한 성능 평가 수단으로는 Inception Score[22]를 활용하였다. 테스트 데이터에 대한 정확도 분석으로 수행할 수 있는 구별 모델의 평가와 달리, 생성 모델으로 생성한 영상에 대한 평가를 객관화하기란 간단하지 않은 문제이다. Tim Sallmans가 제안한 Inception Score는 심층 신경망을 이용한 구별 모델인 Inception V3[23]를 이용하여 생성 모델의 성능을 평가하는 방법이다.

Inception V3 모델은 ImageNet 영상 데이터로 미리 학습된 가중치를 사용하며 그 구조는 Google 사의 GoogLeNet[24]의 구조를 확장하여 설계되었다. Inception Score는 Inception V3 모델을 이용하여 영상들을 분류하고, 그 결과가 일정할수록 정보 획득량(Information gain)이 많고 분류 결과가 다양하게 나올수록 정보 획득량이 적다는 사실을 이용하여 영상 생성 결과의 일관성을 수치화 한다. 수식 4.1은 Inception Score의 계산 방법을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/50126000-7d398f00-02ae-11e9-9970-c3a141b14c1e.png)

본 논문에서 제안하는 영상 생성 방법과 VAE 구조를 기반으로 하는 기존의 방법을 Inception Score를 통해 비교한 결과를 표 4.5에 정리하였다. Inception Score의 평균과 표준 편차를 계산에는 각 영상 생성 방법으로 생성한 10,000개의 서로 다른 영상을 이용하였다. VAE를 단독으로 사용하거나 기존의 VDSR을 사용한 영상 생성 방법에 비해 본 논문의 제안 모델이 더 높은 Inception Score를 획득하여 생성 영상이 비교적 일관됨을 알 수 있다.

![image](https://user-images.githubusercontent.com/12293076/50126020-8aef1480-02ae-11e9-85e9-3aeaeb3afefe.png)

