# 2. 관련 연구

## 2.1. 생성 모델을 이용한 영상 생성 방법

대부분의 영상 생성 모델은 최대우도추정법(Maximum Likelihood Estimation)을 이용하여 목표하는 최적의 매개변수 (theta)를 학습한다. 여기서 우도(Likelihood)는 주어진 표본으로 보았을 때 모집단의 매개변수에 대한 추정이 얼마나 그럴듯한지에 대한 정도를 나타낸다. 모델이 예측한 결과의 분포를 P, 학습 데이터의 분포를 Q라고 할 때, 최대우도추정은 수식 2.1과 같이 쓸 수 있다. 로그 연산은 대소 관계에 변화를 주지 않으므로 1보다 작은 값을 가지는 확률 값의 계산 편의를 위해 로그를 취하여 수식 2.1을 도출한다.

![image](https://user-images.githubusercontent.com/12293076/47901298-ee6de000-dec2-11e8-900e-532fd90c6eba.png)

생성 모델에서는 수식 2.1을 최대화하는 매개변수를 추정하여 모델이 실제영상과 가까운 영상을 생성하도록 한다. 최대우도추정은 표본의 크기가 커질수록 추정 모수가 실제 모수에 가까워지는 특성이 있기 때문에 학습에 사용하는 데이터의 양이 많을수록 유리하지만 그만큼 데이터의 질 또한 중요해진다.

## 2.2. 적대적 생성 신경망

적대적 생성 신경망(GAN: Generative Adversarial Network)[2]은 대표적인 생성 모델 중 하나로서, 그림 2.2와 같이 심층 신경망으로 구성된 생성자(Generator)와 구별자(Discriminator)가 서로 경쟁하며 학습하는 구조로 이뤄져있다. 생성자는 주어진 잠재 벡터로부터 그럴듯한 가짜 영상 x'을 생성하여 구별자를 속이는 역할을 수행하고 구별자는 생성자가 만든 가짜 영상 x'와 실제 영상 x를 구별하는 역할을 수행하여 두 모델이 경쟁을 통해 함께 성장할 수 있도록 설계한다. GAN은 학습 단계에서 생성자의 입력값으로 확률 분포 p_z를 따르는 잠재 벡터를 사용한다. 그리고 생성자가 생성하는 영상을 실제 영상과 유사하도록 학습하는 과정에서 생성 영상의 분포가 실제 영상의 분포와 근접해지도록 유도한다. 생성자와 구별자는 수식 2.2의 이진 크로스 엔트로피를 이용하여 손실 함수(Loss Function)를 계산한다. 

![image](https://user-images.githubusercontent.com/12293076/50125188-12d31f80-02ab-11e9-9d62-b589277a7669.png)
<br/> _그림 2.1 GAN의 구조_

![image](https://user-images.githubusercontent.com/12293076/50125217-2a120d00-02ab-11e9-9e1a-64fed183c5f8.png)

이진 크로스 엔트로피는 입력값 x와 목적 값 y의 차이를 계산하는 방식 중 하나이다. 입력 값과 목적 값은 모두 0~1의 값을 가지며 두 값의 차이가 적을수록 결과 값은 0에 가깝다. 수식 2.3과 2.4는 각각 구별자와 생성자의 손실 함수를 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/50125231-34cca200-02ab-11e9-84c8-b3aa4f121ed6.png)

구별자는 실제 영상은 1, 생성자가 만든 가짜 영상에는 0을 출력하여 구별하도록 학습한다. 한편, 생성자는 구별자가 자신이 만든 가짜 영상에 1을 출력하도록 즉, 구별자가 구별해내지 못할 영상을 만들도록 학습한다.

## 2.3 Variational Auto-encoder
### 2.3.1. Auto-encoder

자동인코더(Auto-Encoder)[11]는 고차원의 데이터를 저차원으로 표현하여 저장 효율을 높이려는 목적으로 고안된 압축, 재생 모델이다. 자동인코더는 영상 x에서 저차원 벡터의 잠재변수 z를 얻는 인코더와 잠재변수 z로부터 영상 x를 재생하는 디코더로 구성된다.  자동인코더의 인코더와 디코더는 목적에 따라 여러개의 컨볼루션 계층과 상승 컨벌루션 계층을 사용한다. 그림 2.1은 자동인코더의 구조를 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/50125298-81b07880-02ab-11e9-95cb-1e7aa381b50b.png)
<br/> _그림 2.2 자동인코더의 구조_

Auto-encoder는 데이터 압축 및 저장 효율성의 측면에서 좋은 성능을 보이는 구조이지만 생성 모델로서의 효용가치는 떨어진다. 그 이유는 인코더가 생성하는 잠재 벡터 의 분포가 무작위이기 때문에 디코더에 의해 생성되는 생성 영상 간의 상관관계를 설명할 수 없기 때문이다.

### 2.3.2. 변분 자동 인코더

변분 자동인코더(VAE: Variational Auto-Encoder)[1]는 적대적 생성 신경망(GAN: Generative Adversarial Network)[2]와 함께 최대우도측정법을 이용하여 영상을 생성하는 대표적인 생성 모델 중 하나이다. 

기존의 자동인코더는 의 분포가 무작위로 형성되어 디코더를 이용한 생성 모델 활용이 어려웠다. 변분 자동인코더는 의 분포가 가우시안 분포를 따른다고 가정하여 임의의 저차원 벡터로부터 디코더의 영상 생성이 용이하게 자동인코더를 설계하는 방법이다. 잠재변수의 확률분포를 고려함으로써 생성영상 사이의 상관관계를 표현할 수 있게 되었다. 

생성 모델로서 변분 자동인코더가 작동하기 위해 필요한 것은 수식 2.2와 같은 결합 분포를 알아내는 것이다. 즉,  뿐만 아니라 데이터의 확률 분포 도 알아야 하는 것이다. 결국 를 구하는 것이 생성 모델로서의 최종 목표가 된다.

![image](https://user-images.githubusercontent.com/12293076/47901582-b4e9a480-dec3-11e8-9028-4c2f741983da.png)

p(x)를 구하기 위해서 p(z), p(z|x), p(x|z) 세 가지가 필요한데, 변분 자동인코더에서 는 가우시안으로 가정된 잠재변수의 분포, 는 영상을 잠재변수로 압축하는 인코더, 는 잠재변수로부터 영상을 복원하는 디코더로 정의한다. 
수식 2.3은 p(x)를 구하는 과정이다. q는 영상에 대해 추정한 확률 분포를 의미한다. 두 확률분포간의 유사도를 측정하는 방법인 쿨백-라이블러 발산(KL-Divergence)에 의해 수식 2.3은 수식 2.4로 정리될 수 있다. 

![image](https://user-images.githubusercontent.com/12293076/47901605-c7fc7480-dec3-11e8-9189-17769ff0511e.png)

수식 2.4의 첫 번째 항은 q(z|x)로부터 샘플링한 z를 기반으로 한 조건부 확률 p(x|z)의 우도(Likelihood)이다. 즉, 변분 자동인코더에서 디코더의 생성 영상과 입력 영상 간의 차이를 의미하는 Reconstruction Loss를 표현하는 기댓값이다. 두 번째 항은 현재 근사하려고 하는 q(z|x)확률분포 와 p(z)의 유사성을 의미한다. 변분 자동인코더에서 잠재변수 z는 가우시안 분포를 따른다고 가정하므로 쿨백-라이블러 발산 정의에 따라 계산이 가능하다. 수식 2.4의 세 번째 항은 확률분포 q(z|x)와 p(z|x)사이의 유사성을 말하는데, 여기서 p(z|x)를 구하려면 p(x)를 알아야하기에 값을 계산할 수 없다. 하지만 쿨백-라이블러 발산의 값은 0보다 큰 특징이 있으므로 전체항을 최대화하는 목적에 따라 세 번째 항은 무시할 수 있다.
몬테 카를로 추정(MonteCarlo Estimation)과 쿨백-라이블러 발산의 정의에 따라 변분 자동인코더의 학습 손실(Loss)은 수식 2.5와 같이 정의할 수 있다.

![image](https://user-images.githubusercontent.com/12293076/47901687-fbd79a00-dec3-11e8-9706-3b02f396afc9.png)

## 2.4. 신경망을 이용한 초해상도 복원

SISR(Single Image Super-Resolution) 문제라고도 불리는 저해상도 영상의 초해상도 복원(Super-resolution) 방법론은 영상 처리 분야에서 활발히 연구되어오던 주제이다. 기존의 해결 방법으로는 전통적인 단일 커널(Kernel) 곱 연산을 이용한 영상처리 기법 등이 있으며, 최근 SRCNN(Super-Resolution Convolutional Neural Network)[8]의 발표를 기점으로 신경망을 사용한 초해상도 복원이 각광받기 시작했다. 

### 2.4.1. SRCNN
SRCNN은 SISR 문제에 처음으로 심층 학습을 적용했다는 점에서 상징적인 의미가 있는 초해상도 복원 기법이다. SRCNN은 3개의 컨벌루션 계층(Convolution Layer)을 기반으로 한다. 각각의 컨벌루션 계층은 영상의 일부분을 일정 크기로 잘라낸 Patch에서 특징(Feature)를 추출하는 계층, 비선형 맵핑(Mapping)을 수행하는 계층, 고해상도 영상을 생성하는 계층으로 구성되어 있다. 그림 2.3는 SRCNN의 기본 구조를 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/48176092-0ecdec80-e352-11e8-8f88-13d333eac7a1.png)
<br/> _그림 2.3 SRCNN의 기본 구조_

## 2.5 VDSR

SRCNN의 등장 이후 VDSR(Very Deep Super-Resolution)[6]은 매우 깊은 신경망 구조를 바탕으로 SISR 문제에서 매우 뛰어난 성능을 보이며 주목받았다. 그림 2.4는 VDSR의 구조이다.

![image](https://user-images.githubusercontent.com/12293076/50125363-d653f380-02ab-11e9-832a-744eeb9a7767.png)
<br/> _그림 2.4 VDSR의 구조_

VDSR의 구조는 매우 단순하다. 컨볼루션 계층과 ReLU 활성화 함수를 하나의 쌍으로 여러 번 나열하여 깊은 컨벌루션 모델을 구성하고 마지막 계층의 결과물과 입력 영상을 요소별(Element-wise)로 덧셈하는 레지듀얼 학습 기법을 사용한다. 낮은 해상도의 초기 입력 영상은 Bicubic 선형 보간법을 사용하여 목표 해상도와 일치시킨 후 모델에 사용한다. 컨볼루션 계층과 ReLU 활성화 함수의 개수를 늘릴수록 더 높은 성능을 발휘하지만 일반적인 경우 약 20여 쌍의 계층을 사용하도록 권장한다. 

손실 함수로는 출력 영상과 원본 영상의 유클리드 거리(Euclidean distance)를 사용한다. 수식 2.9는 유클리드 거리를 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/50125366-da801100-02ab-11e9-83e5-a4ef0a994e64.png)

일반적인 심층 학습의 경우, 모델의 구조가 매우 깊어지면 효과적인 학습이 어렵지만 VDSR에서는 레지듀얼 학습법 (Residual Learning)[9]과 Gradient Clipping 기법[10]을 통해 이를 극복했다.

### 2.5.1. 레지듀얼 학습법

레지듀얼 학습법은 초기 입력 영상과 모델 마지막 계층의 결과물을 요소별(Element-wise)로 덧셈하는 방법이다. 초해상도 복원 문제의 경우, 입력으로 들어오는 저해상도 영상이 최종적으로 생성되는 고해상도 영상과 비교했을 때, 많은 차이가 나지 않기 때문에 요소별 덧셈을 통해서 모델이 영상의 디테일 생성에만 집중할 수 있도록 유도하는 효과를 가진다. 그림 2.5는 레지듀얼 학습법을 이용한 모델의 가중치 계층 배치도이다.

![image](https://user-images.githubusercontent.com/12293076/50125400-07342880-02ac-11e9-99c5-91eacb460c52.png)
<br/> _그림 2.5 레지듀얼 학습 구조_

### 2.5.2. Gradient Clipping 기법

Gradient Clipping 기법[10]은 매우 깊은 구조의 인공 신경망 모델의 학습에서 매개변수의 갱신 방향을 나타내는 학습 기울기(Gradient)가 발산해버리는 것을 막기 위한 방법 중 하나이다. 심층 신경망은 각 학습 단계에서 계산된 학습 기울기에 따라 매개변수 갱신 정도를 정한다. 신경망 구조가 깊어짐에 따라 찾고자하는 목적함수의 비선형도가 강해지면 그 미분값이 매우 크거나 작아지는 경향이 있다. 이러한 가파른 지형의 목적함수 위에서 탐색이 이뤄지는 경우, 매개변수에 여러 개의 가중치가 곱해지면서 그 값이 너무 크게 움직이게 되어 이전의 학습이 무효화 될 경우가 생기게 된다. 이러한 경우를 Gradient Vanishing/Exploding Problem이라고 한다. 그림 2.6은 Gradient Vanishing/Exploding Problem의 예를 가시화한다. 

![image](https://user-images.githubusercontent.com/12293076/47901996-a2239f80-dec4-11e8-87ed-50b229a834d9.png)
<br/> _그림 2.6 Gradient Exploding Problem_

Gradient Vanishing/Exploding Problem 문제에 대처하는 한 가지 방법은 매개변수의 갱신 정도를 조절하는 학습률(Learning Rate)을 매우 작게 설정하는 것이다. 하지만 이 방법은 학습 속도를 매우 늦추고 Local Minima에 빠질 우려를 낳는다. 

Gradient Clipping은 각 학습 단계에서 Gradient의 최댓값을 제한하고, 최대치가 넘은 Gradient의 크기를 적절히 조정해주는 것이다. 이를 통해 최적화 알고리즘은 해당 단계에서 가야하는 방향은 그대로 유지하면서 매개변수를 갱신하는 정도를 스스로 조절하게 된다. 알고리즘 2.1은 Gradient Clipping의 종류 중 하나인 Norm-Clipping의 알고리즘이다. 

![image](https://user-images.githubusercontent.com/12293076/47902078-c54e4f00-dec4-11e8-8edd-94ca26ccce91.png)

