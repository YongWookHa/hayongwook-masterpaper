# 3. 제안하는 영상 생성 방법
## 3.1. 개요
본 논문에서 제안하는 영상 생성 방법에 대한 흐름은 그림 3.1과 같이 나타낼 수 있다.
![image](https://user-images.githubusercontent.com/12293076/48464356-a5068480-e822-11e8-9dd4-3f4aa0f32889.png)
<br/> _그림 3.1 제안하는 영상 생성 방법 흐름도_

먼저 가우시안 분포를 따르는 잠재변수를 생성하여 변분 자동인코더의 입력으로 사용한다. 계층Ⅰ의 변분 자동인코더에서 생성된 저해상도 영상은 계층Ⅱ의 VDSR 초해상도 복원 모델에 의해 고해상도 영상으로 만들어진다. 

## 3.2. 변분 자동 인코더
변분 자동인코더(VAE: Variational Auto-Encoder)[1]는 기존의 자동인코더에서 잠재변수 의 분포를 고려하는 방법이다. 본 논문에서는 잠재변수가 가우시안 분포를 따르도록 설계하였다. 그림 3.1은 VAE의 구조이다.

![image](https://user-images.githubusercontent.com/12293076/47965676-32144580-e08d-11e8-8af4-897c012c4001.png)
<br/> _그림 3.2 VAE의 구조_

VAE의 인코더와 디코더는 각각 컨벌루션 계층과 상승 컨벌루션 계층으로 이루어져있다. 컨벌루션 계층을 통해 고차원 입력 데이터로부터 특징을 추출하여 저차원 잠재변수로 압축하고 상승 컨벌루션 계층을 통해 압축된 저차원 잠재변수로부터 고차원의 이미지를 생성한다. 인코더와 디코더가 동시에 학습을 진행하게 되며 생성 모델로 활용할 때에는 가우시안 분포를 따르는 잠재변수를 무작위로 생성하여 디코더를 통해 새로운 이미지를 생성한다.

### 3.2.1. 컨벌루셔널 뉴럴 네트워크
컨벌루셔널 뉴럴 네트워크(CNN: Convolutional Neural Network)[12]는 인간의 시신경과 뉴런의 구조를 모방하여 설계된 인공 신경망 구조이다. 컨벌루션은 주어진 목적에 따라 상응하는 커널(Kernel)을 선택하여 곱 연산을 수행하는 것을 의미한다. CNN은 컨벌루션(Convolution) 계층을 통해 데이터로부터 효과적으로 특징을 추출한다. 수식 3.1은 컨벌루션 연산을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/47965688-52440480-e08d-11e8-94cc-6dfb3b729751.png)

주어진 데이터 X에 하나 이상의 커널을 적용하여 추출한 특징들의 집합을 특징 맵(Feature map)이라고 한다. 기존의 컨벌루션 연산은 주로 영상 처리 분야에서 영상의 sharpen, blur 효과를 주거나 edge 검출 등의 목적에 자주 사용되던 연산이다. 기계학습에서는 컨벌루션 연산을 통해 형성된 특징 맵은 그 성능에 큰 영향을 미치기 때문에 특징 맵을 형성하는 다양한 방법론이 연구되었다.[13][14][15]

CNN에서는 기계학습에서 입력 데이터의 전처리 과정으로서 특징 맵 검출의 중요도를 매우 강조한다. 따라서 최적의 특징 맵을 생성할 수 있는 컨벌루션 커널을 학습하는 모델을 설계하는 것을 목표로 한다. 이것을 위해서 CNN은 컨벌루션 계층을 통해 특징 맵의 차원을 늘리고, 풀링(Pooling) 계층을 통해 학습을 조절하고 차원을 감축하며 활성화 함수(Activation Function)을 통해 계층 별로 전달되는 학습 값을 조절하는 방식으로 구성된다. 그림 3.3은 CNN의 구조이다.

![image](https://user-images.githubusercontent.com/12293076/47965692-612ab700-e08d-11e8-9717-1a977321d96e.png)
<br/> _그림 3.3 CNN의 구조_

CNN은 입력 데이터의 특징에 따라 사용하는 풀링 계층과 활성화 함수의 종류가 달라진다. 표 3.1과 표 3.2는 풀링 계층과 활성화 함수의 종류를 정리한다.

![image](https://user-images.githubusercontent.com/12293076/47965704-80c1df80-e08d-11e8-957c-535c630ce47b.png)

![image](https://user-images.githubusercontent.com/12293076/47966565-3e9d9b80-e097-11e8-9023-3d5c806bdbc2.png)


### 3.2.2. 상승 컨벌루셔널 뉴럴 네트워크
상승 컨벌루셔널 뉴럴 네트워크(Up Convolutional Neural Network)[16]는 컨벌루션 연산이 특징을 추출하는 과정에서 착안하여 설계된 저차원의 특징 맵으로부터 고차원의 특징 맵을 생성하는 신경망 구조이다. 학습 과정은 컨벌루셔널 뉴럴 네트워크와 같으나 kernel의 크기와 보폭(stride), 패딩(padding)의 설정값에 따라 생성되는 데이터의 크기를 임의로 정할 수 있다. 그림 3.4은 상승 컨벌루션 연산의 예시이다.

![image](https://user-images.githubusercontent.com/12293076/47965715-9f27db00-e08d-11e8-9313-bdd8417cf05e.png)
<br/> _그림 3.4 상승 컨벌루션 연산의 예시_

### 3.2.3. 인코더 구조 상세 설계
인코더는 여러 개의 컨벌루션 계층을 사용하여 고차원 데이터의 특징을 추출해 저차원의 잠재변수로 압축하는 작업을 담당한다. 본 논문이 제안하는 모델의 인코더는 RGB 정보를 포함한 64×64 크기의 영상을 512개의 차원을 가진 잠재변수로 변환하며, 총 5개의 컨벌루션 계층과 1개의 완전 연결 계층으로 이루어져있다. 각 컨벌루션 계층과 완전 연결계층에는 Leaky ReLU 활성화 함수와 배치 정규화(Batch Normalization) 계층을 추가하여 학습 속도를 높이고 과적합(Overfitting)[17] 현상을 줄였다. 

각 컨벌루션 연산에 사용되는 커널(Kernel)의 크기는 5x5, 보폭(Stride)은 2로 설정하였다. 컨벌루션 계층을 거치면서 특징 맵의 개수가 2배씩 커짐에 따라 최초 특징 맵의 개수는 32개로 설정하였고 컨벌루션 계층을 거치며 최종 출력 결과가 512개의 차원을 가지도록 하였다. 마지막 출력 계층에는 Average 풀링 계층을 추가하여 네트워크의 매개변수 개수를 줄이고 과적합 현상을 방지했다. 그림 3.5는 인코더의 상세 구조를 나타낸다. 

![image](https://user-images.githubusercontent.com/12293076/48464444-e8f98980-e822-11e8-9dc4-850006d20cc4.png)
<br/> _그림 3.5 인코더 상세 구조_

### 3.2.4. 디코더 구조 상세 설계
디코더는 상승 컨벌루션 계층을 나열하여 저차원의 잠재변수를 고차원의 데이터로 재생(Reconstruct)하는 역할을 수행한다. 제안하는 모델에서 디코더는 인코더가 생성한 512차원의 잠재변수를 입력으로 받아 RGB 정보를 포함한 64×64 영상으로 재생한다. 총 5개의 상승 컨벌루션 계층을 사용했는데, 초기 4개의 상승 컨벌루션 계층에는 ReLU 활성화 함수와 배치 정규화 계층을 적용하였고 마지막 상승 컨벌루션 계층에는 활성화 함수로 Hyperbolic tangent를 사용하며 배치정규화는 적용하지 않았다. 모든 상승 컨벌루션 계층에는 5x5 크기의 커널을 사용하였고 보폭은 2로 설정하였다.

상승 컨벌루션 연산에 의해 결과 영상의 크기가 2배씩 증가함에 따라 첫 상승 컨벌루션 계층의 특징 맵의 개수는 256개로 지정하였으며, 이후 계층의 특징 맵의 개수를 각각 128, 64, 32로 절반씩 줄였고, 마지막 계층은 3개의 특징 맵을 가지게 함으로써 각 픽셀별 RGB 정보를 나타내도록 하였다. 그림 3.6은 디코더의 상세 구조이다.

![image](https://user-images.githubusercontent.com/12293076/48464489-09c1df00-e823-11e8-82c9-8433201be904.png)
<br/> _그림 3.6 디코더 상세 구조_

## 3.3. 신경망을 이용한 초해상도 복원
신경망을 이용한 초해상도 복원 모델은 VAE에서 생성된 64×64 저해상도 영상을 64×64 고해상도 영상으로 업 스케일(up-scale)하는 작업을 수행한다. 본 논문에서 제안하는 모델에서 신경망을 이용한 초해상도 복원 모델은 VDSR(Very Deep Super-Resolution)[6]의 구조를 기본으로 한다. 기존의 VDSR보다 많은 레지듀얼 블록을 적용하여 입력 영상에 모델을 최적화시켰다.

### 3.3.1 레지듀얼 학습
기존의 VDSR에서는 하나의 레지듀얼 블록을 사용하여 초기 입력 영상과 모든 컨벌루션 계층을 통과한 결과 영상을 더하였다. Berkeley Segmentation Dataset(BSDS)등 다양한 종류의 영상으로 구성된 학습 데이터를 사용하는 기존의 VDSR은 범용적인 SISR 문제에 대응하기에 적합하도록 설계되었다. 하지만 본 논문에서 사용하는 얼굴 영상 데이터 셋인 CelebA으로 학습된 VAE가 생성하는 영상은 가우시안 확률분포의 균일한 영상이다. 표 3.3은 각 데이터 셋의 구성 비교를 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/48464527-3249d900-e823-11e8-8344-53b5c5cde7ea.png)

본 논문의 모델에서 VDSR 초해상도 복원 모델에 입력되는 영상은 VAE에서 생성된 영상이므로 목표 영상이 존재하지 않고, 입력 영상에서 얻을 수 있는 디테일 정보가 한정적이다. 본 논문이 제안하는 영상 생성 모델에서 사용하는 VDSR의 최종 목표는 해상도 up-scale시 잡음을 줄이고 입력 영상과 유사한 고해상도 영상을 얻는 것이므로 영상이 컨벌루션 계층을 통과하며 매끄럽고 자연스럽게 생성되는데 초점을 두었다. 따라서 기존의 VDSR 모델보다 레지듀얼 블록을 더 촘촘히 배치하여 입력 영상에 대한 초해상도 복원 모델의 성능 개선을 의도했다.

### 3.3.2. 초해상도 복원 모델 상세 설계
그림 3.7은 초해상도 복원 모델의 상세 구조를 나타낸다. 총 22개의 컨벌루션 계층과 같은 수의 ReLU을 두었으며 두 번째 컨벌루션 계층부터 4개 계층을 엮은 레지듀얼 블록을 총 5개 배치하였다. 마지막 컨벌루션 계층에 대한 ReLU 활성화 함수 이후에는 초기 입력 영상을 더한 후 출력하게 하여 모델이 자연스러운 디테일을 생성하는 데 집중하도록 유도하였다.

![image](https://user-images.githubusercontent.com/12293076/48464561-51486b00-e823-11e8-84f4-60151d5e44c3.png)
<br/> _그림 3.7 초해상도 복원 모델 상세 구조_

## 3.4 학습 방법
제안하는 모델의 학습에 사용되는 전역 매개변수는 표3.4와 같이 초기화하여 사용한다. 네트워크의 학습 알고리즘으로 사용되는 적응적 모멘트 추정 방법의 진행은 알고리즘 3.1과 같다.

![image](https://user-images.githubusercontent.com/12293076/48464581-6de4a300-e823-11e8-9b29-cae6ab7381ef.png)

![image](https://user-images.githubusercontent.com/12293076/48464611-7b019200-e823-11e8-8f2a-5a62a56bb8e5.png)

표 3.5는 각 모델의 심층 학습에 사용되는 손실 함수(Loss Function)를 나타낸다. VDSR의 경우, 기존에 두 영상의 오차를 계산할 때 사용되는 MSE(Mean Squared Error) 대신에 가우시안 잡음에 민감한 PSNR(Peak Signal to Noise)를 사용하였다. 수식 3.2는 영상에 대한 PSNR 계산식을 나타낸다.

![image](https://user-images.githubusercontent.com/12293076/48464631-881e8100-e823-11e8-9d74-706f303ffc56.png)

![image](https://user-images.githubusercontent.com/12293076/48464654-910f5280-e823-11e8-92ab-ce219f05bf79.png)

VDSR이 학습에 이용하는 데이터로 VAE가 생성한 영상을 사용하지 않기 때문에 VAE와 VDSR의 학습을 일괄적으로 수행할 수 있으나, 한정된 컴퓨팅 자원에서 학습 대상 계층이 많아지면 그에 따라 배치 크기를 줄여야만 하는 성능 손실이 발생하기 때문에 본 논문의 실험에서는 두 계층의 학습을 분리하여 진행하였다.
